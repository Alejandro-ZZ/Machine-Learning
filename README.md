# Machine Learning Exercises

Development of practical work (TP) related to the Machine Learning area.

### 1. TP-1: [Anscombe's quartet](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-1)

### 2. TP-2: [Exploratory analysis and parametric classifier](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-2)

### 3. TP-3: [K-nearest neighbors (KNN)](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-3)

### 4. TP-4: [Nonparametric classifiers](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-4)

### 5. TP-5: [Clustering algorithms](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-5)

### 6. TP-6: [Regressors and dimensionality reduction](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-6)

| üí¨ **Description** | üìÅ **Data** | üë®üèª‚Äçüíª **Code** |
|--|--|:--:|
| [TP-1: Anscombe's quartet](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-1#tp-1-anscombes-quartet)<br>Analysis of the importance of the outliers effect and data visualization.| Anscombe's datasets.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-1/1_Anscombe_quartet.ipynb)|
| [TP-2.1: Data analysis](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-2#exploratory-analysis)<br>General exploratory analysis to find data showing abnormal behavior.| Sanitary and epidemiological situation of the municipality of Bah√≠a Blanca, Argentina.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-2/2_1_Exploratory_analysis.ipynb)|
| [TP-2.2: Parametric classifier](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-2#parametric-classifiers)<br>Minimum error classifier design and performance analysis against variations of the mean and standard deviation of the generated data.| *"Randomly"* generated Gaussian distributed data.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-2/2_2_Least_error_classifier.ipynb)|
| [TP-3.1: KNN Overview](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/readme.md#knn-overview)<br>Creation of K-nearest neighbors (KNN) classifiers and performance evaluation against some training parameters.| Random samples from a normal (Gaussian) distribution.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/3_1_KNN_Overview.ipynb)|
| [TP-3.2: KNN GridSearch](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/readme.md#knn-gridsearch)<br>Evaluation of hyperparameters and their combination for a k-nearest neighbors (knn) classifier. K-Fold cross-validation is implemented to find the influence of the data on the model.| Random samples from a normal (Gaussian) distribution.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/3_2_KNN_GridSearch.ipynb)|
| [TP-3.3: Spotify songs](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/readme.md#spotify-songs)<br>Development and tunning of a k-nearest neighbors (knn) classifier to predict whether a given song will be liked or not. Feature engineering is implemented to select the data that contributes the most information to the model.| More than 2000 Spotify songs from a specific user marked as liked or disliked.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/3_3_Spotify_songs.ipynb)|
