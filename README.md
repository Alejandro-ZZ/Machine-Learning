# Machine Learning Exercises

Development of practical works (TP) related to Machine Learning field.

| üí¨ **Description** | üìÅ **Data** | üë®üèª‚Äçüíª **Code** |
|--|--|:--:|
|[![](https://img.shields.io/badge/data_analysis-026AA7?style=flat)](#)<br>[TP-1: Anscombe's quartet](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-1#tp-1-anscombes-quartet)<br>Analysis of the importance of the outliers effect and data visualization.| Anscombe's datasets.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-1/1_Anscombe_quartet.ipynb)|
|[![](https://img.shields.io/badge/data_analysis-026AA7?style=flat)](#)<br>[TP-2.1: Data visualization](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-2#exploratory-analysis)<br>General exploratory analysis to find data showing abnormal behavior.| Sanitary and epidemiological situation of the municipality of Bah√≠a Blanca, Argentina.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-2/2_1_Exploratory_analysis.ipynb)|
|[![](https://img.shields.io/badge/classification-238636?style=flat)](#)<br>[TP-2.2: Parametric classifier](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-2#parametric-classifiers)<br>Minimum error classifier design and performance analysis against variations of the mean and standard deviation of the generated data.| *"Randomly"* generated Gaussian distributed data.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-2/2_2_Least_error_classifier.ipynb)|
|[![](https://img.shields.io/badge/classification-238636?style=flat)](#)<br>[TP-3.1: KNN Overview](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/readme.md#knn-overview)<br>Creation of K-nearest neighbors (KNN) classifiers and performance evaluation against some training parameters.| Random samples from a normal (Gaussian) distribution.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/3_1_KNN_Overview.ipynb)|
|[![](https://img.shields.io/badge/classification-238636?style=flat)](#)<br>[TP-3.2: KNN GridSearch](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/readme.md#knn-gridsearch)<br>Evaluation of hyperparameters and their combination for a k-nearest neighbors (knn) classifier. K-Fold cross-validation is implemented to find the influence of the data on the model.| Random samples from a normal (Gaussian) distribution.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/3_2_KNN_GridSearch.ipynb)|
|[![](https://img.shields.io/badge/classification-238636?style=flat)](#) [![](https://img.shields.io/badge/dimensionality_reduction-9e00b5?style=flat)](#)<br>[TP-3.3: Spotify songs](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/readme.md#spotify-songs)<br>Development and tunning of a k-nearest neighbors (knn) classifier to predict whether a given song will be liked or not. Feature engineering is implemented to select the data that contributes the most information to the model.| More than 2000 Spotify songs from a specific user marked as liked or disliked.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-3/3_3_Spotify_songs.ipynb)|
|[![](https://img.shields.io/badge/classification-238636?style=flat)](#)<br>[Fog event forecasting](https://github.com/Alejandro-ZZ/Machine-Learning/blob/master/TP-3/readme.md#fog-event-forecasting)<br>Comparison of ensembles to predict the occurrence of fog event. Bagging and boosting algorithms are implemented to achieve this purpose, including some basic hyperparameter tuning.| Meteorological data from the Ezeiza (Buenos Aires, Argentina) weather station with hourly measurements from 1979 to 2011.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning/blob/master/TP-3/Fog_event_forecasting.ipynb)|
|[![](https://img.shields.io/badge/clustering-F67F00?style=flat)](#)<br>[TP-5: Customers segmentation](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-5#customer-segmentation)<br>Construction of clustering algorithms to segment customers based on their annual consumption pattern in product categories. Silhouette coefficient is implemented to evaluate each model performances.| Clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-5/5_Clustering_customer_segmentation.ipynb)|
|[![](https://img.shields.io/badge/regression-cc1717?style=flat)](#) [![](https://img.shields.io/badge/dimensionality_reduction-9e00b5?style=flat)](#)<br>[TP-6: Boston housing prices](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/tree/master/TP-6#regressors-boston-housing)<br>Construction of regression algorithms to predict property sales prices in the city of Boston. Feature selection techniques are implemented to reduce data dimensionality.| Boston Housing dataset with 506 observations and 14 features describing housing prices.| [Jupyter Notebook](https://github.com/Alejandro-ZZ/Machine-Learning-UNS/blob/master/TP-6/6_Regressors_Boston_Housing.ipynb)|
